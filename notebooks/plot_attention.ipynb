{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# Generic\n",
                "from pathlib import Path\n",
                "import typing\n",
                "import json\n",
                "from pathlib import Path\n",
                "import typing\n",
                "import html\n",
                "import copy\n",
                "\n",
                "# Transformers\n",
                "import circuitsvis # keep this import since we need to disable circuitsvis in CI\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Numerical Computing\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "# Our Code\n",
                "from muutils.nbutils.configure_notebook import configure_notebook\n",
                "from muutils.mlutils import pprint_summary\n",
                "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer\n",
                "from maze_dataset import MazeDataset, MazeDatasetConfig\n",
                "from maze_transformer.mechinterp.plot_attention import ProcessedMazeAttention\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# Setup\n",
                "DEVICE = configure_notebook(seed=42, dark_mode=True)\n",
                "PATH_EXAMPLES: Path = Path(\"../examples/\")\n",
                "PATH_DATA: Path = Path(\"../data/\")\n",
                "\n",
                "# We won't be training any models\n",
                "torch.set_grad_enabled(False)\n",
                "\n",
                "# MODEL_PATH: Path = PATH_EXAMPLES / \"multsrc_demo-g6-n10K-a_dfs-h92077_tiny-v1_sweep-v1_2023-05-20-21-30-02/model.final.zanj\"\n",
                "MODEL_PATH: Path = PATH_EXAMPLES / \"model.hallway-jvq.final.zanj\"\n",
                "print(f\"will try to get model from {MODEL_PATH.as_posix()}\")\n",
                "\n",
                "# get the default model from examples\n",
                "MODEL: ZanjHookedTransformer = ZanjHookedTransformer.read(MODEL_PATH)\n",
                "print(f\"loaded model: {MODEL.zanj_model_config.name} with {MODEL.num_params()} parameters\")\n",
                "\n",
                "# generate a smaller test dataset\n",
                "DATASET_TEST_CFG: MazeDatasetConfig = copy.deepcopy(MODEL.zanj_model_config.dataset_cfg)\n",
                "DATASET_TEST_CFG.n_mazes = 100\n",
                "DATASET_TEST: MazeDataset = MazeDataset.from_config(\n",
                "    DATASET_TEST_CFG,\n",
                "    local_base_path=PATH_DATA,\n",
                "    verbose=True,\n",
                ")\n",
                "print(f\"got test dataset: {DATASET_TEST.cfg.name} with {len(DATASET_TEST)} mazes\")\n",
                "\n",
                "# print a summary of the model config\n",
                "pprint_summary(MODEL.zanj_model_config.model_cfg.summary())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# process the attention data for a single maze\n",
                "ATTENTION_DATA: ProcessedMazeAttention = ProcessedMazeAttention.from_model_and_dataset(\n",
                "\tmodel=MODEL, dataset=DATASET_TEST, n_mazes=1,\n",
                ")[0]\n",
                "\n",
                "# print the summary of the attention data\n",
                "pprint_summary(ATTENTION_DATA.summary())\n",
                "\n",
                "# show the actual maze we are looking at\n",
                "plt.imshow(ATTENTION_DATA.input_maze.as_pixels())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plot a highlight of which tokens are being attended to in the sequence\n",
                "ATTENTION_DATA.plot_colored_tokens_multi()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ATTENTION_DATA.plot_attentions_on_maze(\n",
                "    predict_path_len=10,\n",
                "    model=MODEL,\n",
                "    dataset_cfg=DATASET_TEST.cfg,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# this function plots the attention head values for all the token pairs, for each head on each layer\n",
                "ATTENTION_DATA.plot_attentions()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "maze-transformer-2cGx2R0F-py3.11",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
