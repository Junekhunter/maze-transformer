{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic\n",
    "import typing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import json\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# muutils\n",
    "from zanj.zanj import ZANJ, ZANJ_GLOBAL_DEFAULTS\n",
    "\n",
    "# Our Code\n",
    "from muutils.nbutils.configure_notebook import configure_notebook\n",
    "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer, BaseGPTConfig, TrainConfig\n",
    "from maze_dataset import MazeDataset, MazeDatasetConfig\n",
    "from maze_dataset.dataset.configs import MAZE_DATASET_CONFIGS\n",
    "from maze_dataset.generation import LatticeMazeGenerators\n",
    "from maze_transformer.training.train_model import TrainingResult, train_model\n",
    "from maze_transformer.training.wandb_logger import WandbProject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up plots with PLOT_MODE = 'inline', FIG_OUTPUT_FMT = None, FIG_BASEPATH = None\n",
      "DEVICE = device(type='cpu')\n"
     ]
    }
   ],
   "source": [
    "# set global defaults for ZANJ\n",
    "ZANJ_GLOBAL_DEFAULTS.external_array_threshold = 1024\n",
    "ZANJ_GLOBAL_DEFAULTS.external_list_threshold = 1024\n",
    "\n",
    "# paths\n",
    "PATH_EXAMPLES: Path = Path(\"../examples/\")\n",
    "PATH_DATA: Path = Path(\"../data/\")\n",
    "\n",
    "# reproducibility and device\n",
    "DEVICE = configure_notebook(seed=42, dark_mode=True)\n",
    "print(f\"{DEVICE = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(MAZE_DATASET_CONFIGS.keys()) = ['test-g3-n5-a_dfs-h73257', 'demo_small-g3-n100-a_dfs-h44636', 'demo-g6-n10K-a_dfs-h50618']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{list(MAZE_DATASET_CONFIGS.keys()) = }\")\n",
    "\n",
    "# if you want to specify a custom config, you can do so here\n",
    "CFG_CUSTOM: ConfigHolder = ConfigHolder(\n",
    "    name = \"custom\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"custom-dataset\",\n",
    "\t\tgrid_n=6,\n",
    "\t\tn_mazes=10000,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=8,\n",
    "        d_head=4,\n",
    "        n_layers=2,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.RMSprop,\n",
    "        optimizer_kwargs=dict(lr=0.0001),\n",
    "        batch_size=16,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        intervals_count=dict(\n",
    "            print_loss=100,\n",
    "            checkpoint=5,\n",
    "            eval_fast=10,\n",
    "            eval_slow=5,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "CFG_HALLWAY: ConfigHolder = ConfigHolder(\n",
    "    name = \"hallway_v3\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"hallway\",\n",
    "\t\tgrid_n=7,\n",
    "\t\tn_mazes=3_000_000,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "        maze_ctor_kwargs=dict(\n",
    "            do_forks=False,\n",
    "        ),\n",
    "        applied_filters=[{'name': 'collect_generation_meta', 'args': (), 'kwargs': {}}],\n",
    "        seq_len_max=256,\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=128,\n",
    "        d_head=32,\n",
    "        n_layers=6,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer_kwargs=dict(lr=0.0001),\n",
    "        batch_size=32,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        intervals_count=dict(\n",
    "            print_loss=100,\n",
    "            checkpoint=20,\n",
    "            eval_fast=100,\n",
    "            eval_slow=50,\n",
    "        ),\n",
    "        validation_dataset_cfg=100,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for training a \"real\" demo model\n",
    "CFG_DEMO: ConfigHolder = ConfigHolder.get_config_multisource(\n",
    "    cfg_names=(\"test-g3-n5-a_dfs-h73257\", \"tiny-v1\", \"sweep-v1\"),\n",
    ")\n",
    "\n",
    "# this is smaller, for testing\n",
    "CFG_TEST: ConfigHolder = ConfigHolder.get_config_multisource(\n",
    "    cfg_names=(\"demo_small-g3-n100-a_dfs-h44636\", \"nano-v1\", \"test-v1\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is where to specify which config to actually use\n",
    "CFG: ConfigHolder = CFG_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"multsrc_demo_small-g3-n100-a_dfs-h44636_nano-v1_test-v1\",\n",
      "  \"dataset_cfg\": {\n",
      "    \"name\": \"demo_small\",\n",
      "    \"fname\": \"demo_small-g3-n100-a_dfs-h44636\",\n",
      "    \"sdc_hash\": 89724264431769658998652566433510669623512452901670271738715908684739630044636,\n",
      "    \"seed\": 42,\n",
      "    \"seq_len_min\": 1,\n",
      "    \"seq_len_max\": 512,\n",
      "    \"applied_filters\": [],\n",
      "    \"grid_n\": 3,\n",
      "    \"grid_shape\": [\n",
      "      3,\n",
      "      3\n",
      "    ],\n",
      "    \"n_mazes\": 100,\n",
      "    \"maze_ctor_name\": \"gen_dfs\",\n",
      "    \"maze_ctor_kwargs\": {}\n",
      "  },\n",
      "  \"model_cfg\": {\n",
      "    \"name\": \"nano-v1\",\n",
      "    \"act_fn\": \"gelu\",\n",
      "    \"d_model\": 8,\n",
      "    \"d_head\": 4,\n",
      "    \"n_layers\": 2,\n",
      "    \"positional_embedding_type\": \"standard\",\n",
      "    \"weight_processing\": {\n",
      "      \"are_layernorms_folded\": false,\n",
      "      \"are_weights_processed\": false\n",
      "    },\n",
      "    \"n_heads\": 2\n",
      "  },\n",
      "  \"train_cfg\": {\n",
      "    \"name\": \"test-v1\",\n",
      "    \"optimizer\": \"RMSprop\",\n",
      "    \"optimizer_kwargs\": {\n",
      "      \"lr\": 0.0001\n",
      "    },\n",
      "    \"batch_size\": 16,\n",
      "    \"dataloader_cfg\": {\n",
      "      \"shuffle\": true,\n",
      "      \"num_workers\": 0,\n",
      "      \"drop_last\": false\n",
      "    },\n",
      "    \"intervals\": null,\n",
      "    \"intervals_count\": {\n",
      "      \"print_loss\": 100,\n",
      "      \"checkpoint\": 2,\n",
      "      \"eval_fast\": 4,\n",
      "      \"eval_slow\": 2\n",
      "    },\n",
      "    \"evals_max_new_tokens\": 8,\n",
      "    \"validation_dataset_cfg\": 1\n",
      "  },\n",
      "  \"pretrainedtokenizer_kwargs\": null,\n",
      "  \"maze_tokenizer\": {\n",
      "    \"tokenization_mode\": \"AOTP_UT_uniform\",\n",
      "    \"max_grid_size\": 3,\n",
      "    \"vocab_size\": 20\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(CFG.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to get the dataset 'demo_small-g3-n100-a_dfs-h44636'\n",
      "seeing if we can download the dataset...\n",
      "no download found, or download failed\n",
      "generating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating & solving mazes: 100%|██████████| 100/100 [00:00<00:00, 1562.52maze/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving dataset to ..\\data\\demo_small-g3-n100-a_dfs-h44636.zanj\n",
      "Got dataset demo_small with 100 items. output.cfg.to_fname() = 'demo_small-g3-n100-a_dfs-h91156'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get just the dataset, generating it if needed. \n",
    "# This step can be skipped if you set `do_generate_dataset=True` when calling `train_model`\n",
    "# or if the dataset in question already exists\n",
    "\n",
    "# load the dataset\n",
    "DATASET: MazeDataset = MazeDataset.from_config(CFG.dataset_cfg, verbose=True, local_base_path=PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-26 15:12:42 ERROR Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: miv. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\KNC\\maze-transformer\\notebooks\\wandb\\run-20240726_151244-pq9dpsg6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/miv/understanding-search/runs/pq9dpsg6' target=\"_blank\">olive-lake-20</a></strong> to <a href='https://wandb.ai/miv/understanding-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/miv/understanding-search' target=\"_blank\">https://wandb.ai/miv/understanding-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/miv/understanding-search/runs/pq9dpsg6' target=\"_blank\">https://wandb.ai/miv/understanding-search/runs/pq9dpsg6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-26 15:12:46 INFO config ={'__format__': 'ConfigHolder(SerializableDataclass)', 'dataset_cfg': {'__format__': 'MazeDatasetConfig(SerializableDataclass)', 'name': 'demo_small', 'seq_len_min': 1, 'seq_len_max': 512, 'seed': 42, 'applied_filters': [], 'grid_n': 3, 'n_mazes': 100, 'maze_ctor': {'__name__': 'gen_dfs', '__module__': 'maze_dataset.generation.generators', '__doc__': ['generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `accessible_cells: int | float |None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid. if a float, asserts it is <= 1 and treats it as a proportion of **total cells**', '            (default: `None`)', '        - `max_tree_depth: int | float | None`: the maximum depth of the tree. If `None`, defaults to `2 * accessible_cells`. if a float, asserts it is <= 1 and treats it as a proportion of the **sum of the grid shape**', '            (default: `None`)', '        - `do_forks: bool`: whether to allow forks in the maze. If `False`, the maze will be have no forks and will be a simple hallway.', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        '], 'source_code': ['    @staticmethod', '    def gen_dfs(', '        grid_shape: Coord,', '        lattice_dim: int = 2,', '        accessible_cells: int | float | None = None,', '        max_tree_depth: int | float | None = None,', '        do_forks: bool = True,', '        randomized_stack: bool = False,', '        start_coord: Coord | None = None,', '    ) -> LatticeMaze:', '        \"\"\"generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `accessible_cells: int | float |None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid. if a float, asserts it is <= 1 and treats it as a proportion of **total cells**', '            (default: `None`)', '        - `max_tree_depth: int | float | None`: the maximum depth of the tree. If `None`, defaults to `2 * accessible_cells`. if a float, asserts it is <= 1 and treats it as a proportion of the **sum of the grid shape**', '            (default: `None`)', '        - `do_forks: bool`: whether to allow forks in the maze. If `False`, the maze will be have no forks and will be a simple hallway.', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        \"\"\"', '', '        # Default values if no constraints have been passed', '        grid_shape: Coord = np.array(grid_shape)', '        n_total_cells: int = int(np.prod(grid_shape))', '', '        n_accessible_cells: int', '        if accessible_cells is None:', '            n_accessible_cells = n_total_cells', '        elif isinstance(accessible_cells, float):', '            assert (', '                accessible_cells <= 1', '            ), f\"accessible_cells must be an int (count) or a float in the range [0, 1] (proportion), got {accessible_cells}\"', '', '            n_accessible_cells = int(accessible_cells * n_total_cells)', '        else:', '            assert isinstance(accessible_cells, int)', '            n_accessible_cells = accessible_cells', '', '        if max_tree_depth is None:', '            max_tree_depth = (', '                2 * n_total_cells', '            )  # We define max tree depth counting from the start coord in two directions. Therefore we divide by two in the if clause for neighboring sites later and multiply by two here.', '        elif isinstance(max_tree_depth, float):', '            assert (', '                max_tree_depth <= 1', '            ), f\"max_tree_depth must be an int (count) or a float in the range [0, 1] (proportion), got {max_tree_depth}\"', '', '            max_tree_depth = int(max_tree_depth * np.sum(grid_shape))', '', '        # choose a random start coord', '        start_coord = _random_start_coord(grid_shape, start_coord)', '', '        # initialize the maze with no connections', '        connection_list: ConnectionList = np.zeros(', '            (lattice_dim, grid_shape[0], grid_shape[1]), dtype=np.bool_', '        )', '', '        # initialize the stack with the target coord', '        visited_cells: set[tuple[int, int]] = set()', '        visited_cells.add(tuple(start_coord))  # this wasnt a bug after all lol', '        stack: list[Coord] = [start_coord]', '', '        # initialize tree_depth_counter', '        current_tree_depth: int = 1', '', '        # loop until the stack is empty or n_connected_cells is reached', '        while stack and (len(visited_cells) < n_accessible_cells):', '            # get the current coord from the stack', '            current_coord: Coord', '            if randomized_stack:', '                current_coord = stack.pop(random.randint(0, len(stack) - 1))', '            else:', '                current_coord = stack.pop()', '', '            # filter neighbors by being within grid bounds and being unvisited', '            unvisited_neighbors_deltas: list[tuple[Coord, Coord]] = [', '                (neighbor, delta)', '                for neighbor, delta in zip(', '                    current_coord + NEIGHBORS_MASK, NEIGHBORS_MASK', '                )', '                if (', '                    (tuple(neighbor) not in visited_cells)', '                    and (0 <= neighbor[0] < grid_shape[0])', '                    and (0 <= neighbor[1] < grid_shape[1])', '                )', '            ]', '', \"            # don't continue if max_tree_depth/2 is already reached (divide by 2 because we can branch to multiple directions)\", '            if unvisited_neighbors_deltas and (', '                current_tree_depth <= max_tree_depth / 2', '            ):', \"                # if we want a maze without forks, simply don't add the current coord back to the stack\", '                if do_forks and (len(unvisited_neighbors_deltas) > 1):', '                    stack.append(current_coord)', '', '                # choose one of the unvisited neighbors', '                chosen_neighbor, delta = random.choice(unvisited_neighbors_deltas)', '', '                # add connection', '                dim: int = np.argmax(np.abs(delta))', '                # if positive, down/right from current coord', '                # if negative, up/left from current coord (down/right from neighbor)', '                clist_node: Coord = (', '                    current_coord if (delta.sum() > 0) else chosen_neighbor', '                )', '                connection_list[dim, clist_node[0], clist_node[1]] = True', '', '                # add to visited cells and stack', '                visited_cells.add(tuple(chosen_neighbor))', '                stack.append(chosen_neighbor)', '', '                # Update current tree depth', '                current_tree_depth += 1', '            else:', '                current_tree_depth -= 1', '', '        output = LatticeMaze(', '            connection_list=connection_list,', '            generation_meta=dict(', '                func_name=\"gen_dfs\",', '                grid_shape=grid_shape,', '                start_coord=start_coord,', '                n_accessible_cells=int(n_accessible_cells),', '                max_tree_depth=int(max_tree_depth),', \"                # oh my god this took so long to track down. its almost 5am and I've spent like 2 hours on this bug\", '                # it was checking that len(visited_cells) == n_accessible_cells, but this means that the maze is', '                # treated as fully connected even when it is most certainly not, causing solving the maze to break', '                fully_connected=bool(len(visited_cells) == n_total_cells),', '                visited_cells={tuple(int(x) for x in coord) for coord in visited_cells},', '            ),', '        )', '', '        return output']}, 'maze_ctor_kwargs': {}, 'endpoint_kwargs': {}, 'grid_shape': (3, 3)}, 'model_cfg': {'__format__': 'BaseGPTConfig(SerializableDataclass)', 'name': 'nano-v1', 'act_fn': 'gelu', 'd_model': 8, 'd_head': 4, 'n_layers': 2, 'positional_embedding_type': 'standard', 'weight_processing': {'are_layernorms_folded': False, 'are_weights_processed': False}, 'n_heads': 2}, 'train_cfg': {'__format__': 'TrainConfig(SerializableDataclass)', 'name': 'test-v1', 'evals_max_new_tokens': 8, 'validation_dataset_cfg': 1, 'optimizer': 'RMSprop', 'optimizer_kwargs': {'lr': 0.0001}, 'batch_size': 16, 'dataloader_cfg': {'shuffle': True, 'num_workers': 0, 'drop_last': False}, 'intervals': None, 'intervals_count': {'print_loss': 100, 'checkpoint': 2, 'eval_fast': 4, 'eval_slow': 2}}, 'name': 'multsrc_demo_small-g3-n100-a_dfs-h44636_nano-v1_test-v1', 'pretrainedtokenizer_kwargs': None, 'maze_tokenizer': {'__format__': 'MazeTokenizer(SerializableDataclass)', 'tokenization_mode': 'AOTP_UT_uniform', 'max_grid_size': 3, 'name': 'maze_tokenizer-AOTP_UT_uniform-g3', 'token_arr': ['<ADJLIST_START>', '<ADJLIST_END>', '<TARGET_START>', '<TARGET_END>', '<ORIGIN_START>', '<ORIGIN_END>', '<PATH_START>', '<PATH_END>', '<-->', ';', '<PADDING>', '(0,0)', '(0,1)', '(1,0)', '(1,1)', '(0,2)', '(2,0)', '(1,2)', '(2,1)', '(2,2)'], 'tokenizer_map': {'<ADJLIST_START>': 0, '<ADJLIST_END>': 1, '<TARGET_START>': 2, '<TARGET_END>': 3, '<ORIGIN_START>': 4, '<ORIGIN_END>': 5, '<PATH_START>': 6, '<PATH_END>': 7, '<-->': 8, ';': 9, '<PADDING>': 10, '(0,0)': 11, '(0,1)': 12, '(1,0)': 13, '(1,1)': 14, '(0,2)': 15, '(2,0)': 16, '(1,2)': 17, '(2,1)': 18, '(2,2)': 19}, 'vocab_size': 20, 'padding_token_index': 10}, '_tokenizer': 'None'}\n",
      "2024-07-26 15:12:46 INFO Initialized logger\n",
      "2024-07-26 15:12:46 INFO Summary logged, getting dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\KNC\\maze-transformer\\maze_transformer\\training\\train_model.py:139: UserWarning:\n",
      "\n",
      "dataset has different config than cfg.dataset_cfg, but the only difference is in applied_filters, so using passed dataset. This is due to fast dataset loading collecting generation metadata for performance reasons\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-26 15:12:46 INFO finished getting training dataset with 100 samples\n",
      "2024-07-26 15:12:46 INFO got validation dataset by splitting training dataset into 99 train and 1 validation samples\n",
      "2024-07-26 15:12:46 INFO Loaded 99 sequences\n",
      "2024-07-26 15:12:46 INFO Creating dataloader\n",
      "2024-07-26 15:12:46 INFO finished dataloader, passing to train()\n",
      "2024-07-26 15:12:46 INFO Initializing model\n",
      "Moving model to device:  cpu\n",
      "2024-07-26 15:12:46 INFO Initializing optimizer\n",
      "2024-07-26 15:12:47 INFO will train for 7 batches, evals_enabled=True, with intervals: {'print_loss': inf, 'checkpoint': 3, 'eval_fast': 1, 'eval_slow': 3}\n",
      "2024-07-26 15:12:47 INFO Starting training\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_fast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\KNC\\maze-transformer\\maze_transformer\\evaluation\\path_evals.py:98: RuntimeWarning:\n",
      "\n",
      "fraction_connections_adjacent_lattice called on path of length less than 2, retuning NaN\n",
      "prediction = array([[1, 2]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-26 15:12:47 INFO Running evals: eval_slow\n",
      "2024-07-26 15:12:47 INFO iteration 0/7: loss=3.198\n",
      "2024-07-26 15:12:47 INFO Saving model checkpoint to ../data/multsrc_demo_small-g3-n100-a_dfs-h44636_nano-v1_test-v1_2024-07-26-15-12-39/checkpoints/model.iter_0.zanj\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_fast\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_fast\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_fast\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_slow\n",
      "2024-07-26 15:12:47 INFO Saving model checkpoint to ../data/multsrc_demo_small-g3-n100-a_dfs-h44636_nano-v1_test-v1_2024-07-26-15-12-39/checkpoints/model.iter_3.zanj\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_fast\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_fast\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_fast\n",
      "2024-07-26 15:12:47 INFO Running evals: eval_slow\n",
      "2024-07-26 15:12:47 INFO Saving model checkpoint to ../data/multsrc_demo_small-g3-n100-a_dfs-h44636_nano-v1_test-v1_2024-07-26-15-12-39/checkpoints/model.iter_6.zanj\n",
      "2024-07-26 15:12:48 INFO Saving final model to ../data/multsrc_demo_small-g3-n100-a_dfs-h44636_nano-v1_test-v1_2024-07-26-15-12-39/model.final.zanj\n",
      "2024-07-26 15:12:48 INFO Done training!\n"
     ]
    }
   ],
   "source": [
    "result: TrainingResult = train_model(\n",
    "\tbase_path=PATH_DATA,\n",
    "    cfg=CFG,\n",
    "\twandb_project=WandbProject.UNDERSTANDING_SEARCH, # change this to WandbProject.DEMO_NOTEBOOKS!\n",
    "\tdo_generate_dataset=False,\n",
    "\tdataset_verbose=True,\n",
    "    dataset=DATASET,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-transformer-2cGx2R0F-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
